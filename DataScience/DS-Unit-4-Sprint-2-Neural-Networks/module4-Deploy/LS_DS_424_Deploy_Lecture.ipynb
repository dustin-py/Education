{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HJzTIkYAsLxw"
   },
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 2, Module 4*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCf3jDMVQHuI"
   },
   "source": [
    "# Neural Network Frameworks (Prepare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GR0XBF5HQHuI"
   },
   "source": [
    "## Learning Objectives\n",
    "* <a href=\"#p1\">Part 1</a>: Implemenent Regularization Strategies\n",
    "* <a href=\"#p2\">Part 2</a>: Deploy a Keras Model\n",
    "* <a href=\"#p3\">Part 3</a>: Write a Custom Callback Function (Optional)\n",
    "\n",
    "Today's class will also focus heavily on Callback objects. We will use a variety of callbacks to monitor and manipulate our models based on data that our model produces at the end of an epoch.\n",
    "\n",
    "> A callback is an object that can perform actions at various stages of training (e.g. at the start or end of an epoch, before or after a single batch, etc). -- [Keras Documentation](https://keras.io/api/callbacks/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TWuoXZCCKCI7"
   },
   "source": [
    "# Regularization Strategies (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3aMJZuPQHur"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Neural Networks are highly parameterized models and can be easily overfit to the training data. The most salient way to combat this problem is with regularization strategies.  \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Regularization.svg/1920px-Regularization.svg.png)\n",
    "\n",
    "There are four common ways of regularization in neural networks which we cover briefly. Here's a quick summary of how to apply them: \n",
    "\n",
    "1. Always use EarlyStopping. This strategy will prevent your weights from being updated well past the point of their peak usefulness.\n",
    "2. Use EarlyStopping, L1/L2 regularization and Dropout\n",
    "3. Use EarlyStopping, Weight Constraint and Dropout\n",
    "\n",
    "Weight Decay and Weigh Constraint accomplish similar purposes - preventing over fitting the parameters by regularizing the values. The mechanics are just slightly different. That's why you would not necessary want to apply them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3FFhK0tLQHus"
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RO74ukb-QHus"
   },
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xgQR_iCHSF1x"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNQYuCARBCs4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WJS0s76rBEgz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(y_train[2])\n",
    "plt.imshow(X_train[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IAeFX9lpBGOu"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = X_train / 255., X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AY1HomhxQHus"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import ReLU\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping-Loss\")\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(128),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(128),\n",
    "    ReLU(negative_slope=.01),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=99, \n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[tensorboard_callback, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mozi0GzYBQFe"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y7ScqKUzQHuv"
   },
   "source": [
    "### L1/L2 regularization\n",
    "\n",
    "```python\n",
    "Dense(64, input_dim=64, kernel_regularizer=regularizers.l2(0.01))\n",
    "Dense(64, input_dim=64, kernel_regularizer=regularizers.l1(0.01))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "\n",
    "The terms \"L2 regularization\" and \"weight decay\" are often used interchagebly, but they only mean the same thing for vanilla SGD optimization. \n",
    "\n",
    "They mean different things for all other optimizers based on SGD (Adam, AdamW, RSMProp, etc).\n",
    "See:\n",
    "- https://www.fast.ai/2018/07/02/adam-weight-decay/\n",
    "- https://arxiv.org/pdf/1711.05101.pdf\n",
    "- https://bbabenko.github.io/weight-decay/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQuacT-JQHuv"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aCJ1aUIfQHuy"
   },
   "source": [
    "### Weight Constraint\n",
    "\n",
    "```python\n",
    "tf.keras.constraints.MaxNorm(\n",
    "    max_value=2, axis=0\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbXBxr1QQHuy"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9-xMnXMsQHu0"
   },
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCRL8SmgQHu0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RFAkmZbVQHu2"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HbV6zsdQQHu4"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "You will apply regularization strategies inside your neural network today, as you try to avoid overfitting it. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MXbzdBdURod"
   },
   "source": [
    "# Deploy (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11LJtU9MUVD5"
   },
   "source": [
    "## Overview\n",
    "\n",
    "You've built a dope image classification model, but it's just sitting your Jupyter Notebook. What now? Well you deploy to some down stream application. TensorFlow supports three ways of deploying it's models: \n",
    "\n",
    "- In-Browswer with TensorFlow.js\n",
    "- API with TensorFlow Serving (TFX) or another Framework\n",
    "- On-Device with TensorFlow Lite\n",
    "\n",
    "You are already familiar with deploying a model as an API from Unit 3, so we will focus on deploying a model in browser. Both methods rely on the same core idea: save your weights and architecture information, load those parameters into application, and perform inference. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHca-4H2UU8p"
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LgqQfelzZTL1"
   },
   "source": [
    "### Train Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Neds_0D2ZR9g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SVSTU7UJZYI1"
   },
   "source": [
    "### Save / Export Your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kI8KHA87UUU1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d6mAg8tpZdzd"
   },
   "source": [
    "### Move Weights to Web Application\n",
    "\n",
    "Not all models are small enough to work well in-browser. Many neural networks are deploy as micro-service APIs. Micro-service APIs are the architecture you studied during Unit 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Iz_yr_7ZmGc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9i7OMOhzc6WT"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "You will be expected to be able to export your model weights and architecutre on the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rXnXxPCZiAb2"
   },
   "source": [
    "# Custom Callbacks (Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z6vO6xbkiFGb"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Custom callbacks all you to access data at any point during the training: on batch end, on epoch end, on epoch start, on batch start. Our use case today is a simple one. Let's stop training once we reach a benchmark accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lCocRF5CiYG_"
   },
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmtMJBBriD2Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOisQxYlibOi"
   },
   "source": [
    "## Challenge\n",
    "\n",
    "Experiment with improving our custom callback function. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_424_Deploy_Lecture.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
