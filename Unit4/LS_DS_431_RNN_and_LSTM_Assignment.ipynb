{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-MNA-DS11",
      "language": "python",
      "name": "u4-s3-mna-ds11"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.0",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.23.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1mVi2tbHF1k"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:18:20.442Z",
          "iopub.execute_input": "2020-06-15T18:18:20.453Z",
          "iopub.status.idle": "2020-06-15T18:18:20.513Z",
          "shell.execute_reply": "2020-06-15T18:18:20.523Z"
        },
        "id": "hZ4SJwOMHF1l"
      },
      "source": [
        "import requests\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-06-15T18:25:49.778Z",
          "iopub.execute_input": "2020-06-15T18:25:49.781Z",
          "iopub.status.idle": "2020-06-15T18:25:51.467Z",
          "shell.execute_reply": "2020-06-15T18:25:51.469Z"
        },
        "id": "qbW_PFqNHF1l"
      },
      "source": [
        "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = r.apparent_encoding\n",
        "data = r.text\n",
        "data = data.split('\\r\\n')\n",
        "toc = [l.strip() for l in data[44:130:2]]\n",
        "# Skip the Table of Contents\n",
        "data = data[135:]\n",
        "\n",
        "# Fixing Titles\n",
        "toc[9] = 'THE LIFE OF KING HENRY V'\n",
        "toc[18] = 'MACBETH'\n",
        "toc[24] = 'OTHELLO, THE MOOR OF VENICE'\n",
        "toc[34] = 'TWELFTH NIGHT: OR, WHAT YOU WILL'\n",
        "\n",
        "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}\n",
        "\n",
        "# Start \n",
        "for e,i in enumerate(data):\n",
        "    for t,title in enumerate(toc):\n",
        "        if title in i:\n",
        "            locations[t].update({'start':e})\n",
        "            \n",
        "\n",
        "df_toc = pd.DataFrame.from_dict(locations, orient='index')\n",
        "df_toc['end'] = df_toc['start'].shift(-1).apply(lambda x: x-1)\n",
        "df_toc.loc[42, 'end'] = len(data)\n",
        "df_toc['end'] = df_toc['end'].astype('int')\n",
        "\n",
        "df_toc['text'] = df_toc.apply(lambda x: '\\r\\n'.join(data[ x['start'] : int(x['end']) ]), axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-06-15T18:26:12.630Z",
          "iopub.execute_input": "2020-06-15T18:26:12.637Z",
          "iopub.status.idle": "2020-06-15T18:26:12.643Z",
          "shell.execute_reply": "2020-06-15T18:26:12.647Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AOML2EEgHF1m",
        "outputId": "ca432032-0d74-4cab-9972-49fd0cf214c7"
      },
      "source": [
        "#Shakespeare Data Parsed by Play\n",
        "df_toc"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>THE TRAGEDY OF ANTONY AND CLEOPATRA</td>\n",
              "      <td>-99</td>\n",
              "      <td>14379</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AS YOU LIKE IT</td>\n",
              "      <td>14380</td>\n",
              "      <td>17171</td>\n",
              "      <td>AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>THE COMEDY OF ERRORS</td>\n",
              "      <td>17172</td>\n",
              "      <td>20372</td>\n",
              "      <td>THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS</td>\n",
              "      <td>20373</td>\n",
              "      <td>30346</td>\n",
              "      <td>THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CYMBELINE</td>\n",
              "      <td>30347</td>\n",
              "      <td>30364</td>\n",
              "      <td>CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>THE TRAGEDY OF HAMLET, PRINCE OF DENMARK</td>\n",
              "      <td>30365</td>\n",
              "      <td>37051</td>\n",
              "      <td>THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\\r\\n\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>THE FIRST PART OF KING HENRY THE FOURTH</td>\n",
              "      <td>37052</td>\n",
              "      <td>41767</td>\n",
              "      <td>THE FIRST PART OF KING HENRY THE FOURTH\\r\\n\\r\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>THE SECOND PART OF KING HENRY THE FOURTH</td>\n",
              "      <td>41768</td>\n",
              "      <td>-100</td>\n",
              "      <td>THE SECOND PART OF KING HENRY THE FOURTH\\r\\n\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>THE LIFE OF KING HENRY THE FIFTH</td>\n",
              "      <td>-99</td>\n",
              "      <td>45176</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>THE LIFE OF KING HENRY V</td>\n",
              "      <td>45177</td>\n",
              "      <td>53383</td>\n",
              "      <td>THE LIFE OF KING HENRY V\\r\\n\\r\\n\\r\\n\\r\\nConten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>THE SECOND PART OF KING HENRY THE SIXTH</td>\n",
              "      <td>53384</td>\n",
              "      <td>56871</td>\n",
              "      <td>THE SECOND PART OF KING HENRY THE SIXTH\\r\\n\\r\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>THE THIRD PART OF KING HENRY THE SIXTH</td>\n",
              "      <td>56872</td>\n",
              "      <td>60257</td>\n",
              "      <td>THE THIRD PART OF KING HENRY THE SIXTH\\r\\n\\r\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>KING HENRY THE EIGHTH</td>\n",
              "      <td>60258</td>\n",
              "      <td>66710</td>\n",
              "      <td>KING HENRY THE EIGHTH\\r\\n\\r\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>KING JOHN</td>\n",
              "      <td>66711</td>\n",
              "      <td>66783</td>\n",
              "      <td>KING JOHN. O cousin, thou art come to set mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>THE TRAGEDY OF JULIUS CAESAR</td>\n",
              "      <td>66784</td>\n",
              "      <td>71427</td>\n",
              "      <td>THE TRAGEDY OF JULIUS CAESAR\\r\\n\\r\\n\\r\\n\\r\\nCo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>THE TRAGEDY OF KING LEAR</td>\n",
              "      <td>71428</td>\n",
              "      <td>77463</td>\n",
              "      <td>THE TRAGEDY OF KING LEAR\\r\\n\\r\\n\\r\\n\\r\\nConten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LOVE’S LABOUR’S LOST</td>\n",
              "      <td>77464</td>\n",
              "      <td>-100</td>\n",
              "      <td>LOVE’S LABOUR’S LOST\\r\\n\\r\\nDramatis Personae....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>THE TRAGEDY OF MACBETH</td>\n",
              "      <td>-99</td>\n",
              "      <td>84427</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>MACBETH</td>\n",
              "      <td>84428</td>\n",
              "      <td>87527</td>\n",
              "      <td>MACBETH.\\r\\nI will not yield,\\r\\nTo kiss the g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>THE MERCHANT OF VENICE</td>\n",
              "      <td>87528</td>\n",
              "      <td>91695</td>\n",
              "      <td>THE MERCHANT OF VENICE\\r\\n\\r\\n\\r\\n\\r\\nContents...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>THE MERRY WIVES OF WINDSOR</td>\n",
              "      <td>91696</td>\n",
              "      <td>94654</td>\n",
              "      <td>THE MERRY WIVES OF WINDSOR\\r\\n\\r\\nDramatis Per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>A MIDSUMMER NIGHT’S DREAM</td>\n",
              "      <td>94655</td>\n",
              "      <td>98114</td>\n",
              "      <td>A MIDSUMMER NIGHT’S DREAM\\r\\n\\r\\n\\r\\n\\r\\nConte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>MUCH ADO ABOUT NOTHING</td>\n",
              "      <td>98115</td>\n",
              "      <td>-100</td>\n",
              "      <td>MUCH ADO ABOUT NOTHING\\r\\n\\r\\n\\r\\n\\r\\nContent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>THE TRAGEDY OF OTHELLO, MOOR OF VENICE</td>\n",
              "      <td>-99</td>\n",
              "      <td>103826</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>OTHELLO, THE MOOR OF VENICE</td>\n",
              "      <td>103827</td>\n",
              "      <td>114239</td>\n",
              "      <td>OTHELLO, THE MOOR OF VENICE\\r\\n\\r\\n\\r\\n\\r\\nCon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>KING RICHARD THE SECOND</td>\n",
              "      <td>114240</td>\n",
              "      <td>117332</td>\n",
              "      <td>KING RICHARD THE SECOND\\r\\n  JOHN OF GAUNT, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>KING RICHARD THE THIRD</td>\n",
              "      <td>117333</td>\n",
              "      <td>121740</td>\n",
              "      <td>KING RICHARD THE THIRD\\r\\n\\r\\nDramatis Persona...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>THE TRAGEDY OF ROMEO AND JULIET</td>\n",
              "      <td>121741</td>\n",
              "      <td>126996</td>\n",
              "      <td>THE TRAGEDY OF ROMEO AND JULIET\\r\\n\\r\\n\\r\\n\\r\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>THE TAMING OF THE SHREW</td>\n",
              "      <td>126997</td>\n",
              "      <td>131870</td>\n",
              "      <td>THE TAMING OF THE SHREW\\r\\n\\r\\n\\r\\n\\r\\nContent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>THE TEMPEST</td>\n",
              "      <td>131871</td>\n",
              "      <td>135693</td>\n",
              "      <td>THE TEMPEST\\r\\n\\r\\n\\r\\n\\r\\nContents\\r\\n\\r\\nACT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>THE LIFE OF TIMON OF ATHENS</td>\n",
              "      <td>135694</td>\n",
              "      <td>138409</td>\n",
              "      <td>THE LIFE OF TIMON OF ATHENS\\r\\n\\r\\nDRAMATIS PE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>THE TRAGEDY OF TITUS ANDRONICUS</td>\n",
              "      <td>138410</td>\n",
              "      <td>141285</td>\n",
              "      <td>THE TRAGEDY OF TITUS ANDRONICUS\\r\\n\\r\\nDramati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>THE HISTORY OF TROILUS AND CRESSIDA</td>\n",
              "      <td>141286</td>\n",
              "      <td>-100</td>\n",
              "      <td>THE HISTORY OF TROILUS AND CRESSIDA\\r\\n\\r\\n\\r\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>TWELFTH NIGHT; OR, WHAT YOU WILL</td>\n",
              "      <td>-99</td>\n",
              "      <td>147448</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>TWELFTH NIGHT: OR, WHAT YOU WILL</td>\n",
              "      <td>147449</td>\n",
              "      <td>154343</td>\n",
              "      <td>TWELFTH NIGHT: OR, WHAT YOU WILL\\r\\n\\r\\n\\r\\n\\r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>THE TWO NOBLE KINSMEN</td>\n",
              "      <td>154344</td>\n",
              "      <td>159531</td>\n",
              "      <td>THE TWO NOBLE KINSMEN:\\r\\n\\r\\nPresented at the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>THE WINTER’S TALE</td>\n",
              "      <td>159532</td>\n",
              "      <td>164546</td>\n",
              "      <td>THE WINTER’S TALE\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nContents\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>A LOVER’S COMPLAINT</td>\n",
              "      <td>164547</td>\n",
              "      <td>164929</td>\n",
              "      <td>A LOVER’S COMPLAINT\\r\\n\\r\\n\\r\\n\\r\\nFrom off a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>THE PASSIONATE PILGRIM</td>\n",
              "      <td>164930</td>\n",
              "      <td>165169</td>\n",
              "      <td>THE PASSIONATE PILGRIM\\r\\n\\r\\nI.\\r\\n\\r\\nDid no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>THE PHOENIX AND THE TURTLE</td>\n",
              "      <td>165170</td>\n",
              "      <td>165263</td>\n",
              "      <td>THE PHOENIX AND THE TURTLE\\r\\n\\r\\n\\r\\n\\r\\nLet ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>THE RAPE OF LUCRECE</td>\n",
              "      <td>165264</td>\n",
              "      <td>167482</td>\n",
              "      <td>THE RAPE OF LUCRECE\\r\\n\\r\\n                   ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>VENUS AND ADONIS</td>\n",
              "      <td>167483</td>\n",
              "      <td>169306</td>\n",
              "      <td>VENUS AND ADONIS\\r\\n\\r\\nEven as the sun with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td></td>\n",
              "      <td>169307</td>\n",
              "      <td>169308</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       title  ...                                               text\n",
              "0        THE TRAGEDY OF ANTONY AND CLEOPATRA  ...                                                   \n",
              "1                             AS YOU LIKE IT  ...  AS YOU LIKE IT\\r\\n\\r\\n\\r\\nDRAMATIS PERSONAE.\\r...\n",
              "2                       THE COMEDY OF ERRORS  ...  THE COMEDY OF ERRORS\\r\\n\\r\\n\\r\\n\\r\\nContents\\r...\n",
              "3                  THE TRAGEDY OF CORIOLANUS  ...  THE TRAGEDY OF CORIOLANUS\\r\\n\\r\\nDramatis Pers...\n",
              "4                                  CYMBELINE  ...  CYMBELINE.\\r\\nLaud we the gods;\\r\\nAnd let our...\n",
              "5   THE TRAGEDY OF HAMLET, PRINCE OF DENMARK  ...  THE TRAGEDY OF HAMLET, PRINCE OF DENMARK\\r\\n\\r...\n",
              "6    THE FIRST PART OF KING HENRY THE FOURTH  ...  THE FIRST PART OF KING HENRY THE FOURTH\\r\\n\\r\\...\n",
              "7   THE SECOND PART OF KING HENRY THE FOURTH  ...  THE SECOND PART OF KING HENRY THE FOURTH\\r\\n\\r...\n",
              "8           THE LIFE OF KING HENRY THE FIFTH  ...                                                   \n",
              "9                   THE LIFE OF KING HENRY V  ...  THE LIFE OF KING HENRY V\\r\\n\\r\\n\\r\\n\\r\\nConten...\n",
              "10   THE SECOND PART OF KING HENRY THE SIXTH  ...  THE SECOND PART OF KING HENRY THE SIXTH\\r\\n\\r\\...\n",
              "11    THE THIRD PART OF KING HENRY THE SIXTH  ...  THE THIRD PART OF KING HENRY THE SIXTH\\r\\n\\r\\n...\n",
              "12                     KING HENRY THE EIGHTH  ...                   KING HENRY THE EIGHTH\\r\\n\\r\\n...\n",
              "13                                 KING JOHN  ...    KING JOHN. O cousin, thou art come to set mi...\n",
              "14              THE TRAGEDY OF JULIUS CAESAR  ...  THE TRAGEDY OF JULIUS CAESAR\\r\\n\\r\\n\\r\\n\\r\\nCo...\n",
              "15                  THE TRAGEDY OF KING LEAR  ...  THE TRAGEDY OF KING LEAR\\r\\n\\r\\n\\r\\n\\r\\nConten...\n",
              "16                      LOVE’S LABOUR’S LOST  ...  LOVE’S LABOUR’S LOST\\r\\n\\r\\nDramatis Personae....\n",
              "17                    THE TRAGEDY OF MACBETH  ...                                                   \n",
              "18                                   MACBETH  ...  MACBETH.\\r\\nI will not yield,\\r\\nTo kiss the g...\n",
              "19                    THE MERCHANT OF VENICE  ...  THE MERCHANT OF VENICE\\r\\n\\r\\n\\r\\n\\r\\nContents...\n",
              "20                THE MERRY WIVES OF WINDSOR  ...  THE MERRY WIVES OF WINDSOR\\r\\n\\r\\nDramatis Per...\n",
              "21                 A MIDSUMMER NIGHT’S DREAM  ...  A MIDSUMMER NIGHT’S DREAM\\r\\n\\r\\n\\r\\n\\r\\nConte...\n",
              "22                    MUCH ADO ABOUT NOTHING  ...   MUCH ADO ABOUT NOTHING\\r\\n\\r\\n\\r\\n\\r\\nContent...\n",
              "23    THE TRAGEDY OF OTHELLO, MOOR OF VENICE  ...                                                   \n",
              "24               OTHELLO, THE MOOR OF VENICE  ...  OTHELLO, THE MOOR OF VENICE\\r\\n\\r\\n\\r\\n\\r\\nCon...\n",
              "25                   KING RICHARD THE SECOND  ...    KING RICHARD THE SECOND\\r\\n  JOHN OF GAUNT, ...\n",
              "26                    KING RICHARD THE THIRD  ...  KING RICHARD THE THIRD\\r\\n\\r\\nDramatis Persona...\n",
              "27           THE TRAGEDY OF ROMEO AND JULIET  ...  THE TRAGEDY OF ROMEO AND JULIET\\r\\n\\r\\n\\r\\n\\r\\...\n",
              "28                   THE TAMING OF THE SHREW  ...  THE TAMING OF THE SHREW\\r\\n\\r\\n\\r\\n\\r\\nContent...\n",
              "29                               THE TEMPEST  ...  THE TEMPEST\\r\\n\\r\\n\\r\\n\\r\\nContents\\r\\n\\r\\nACT...\n",
              "30               THE LIFE OF TIMON OF ATHENS  ...  THE LIFE OF TIMON OF ATHENS\\r\\n\\r\\nDRAMATIS PE...\n",
              "31           THE TRAGEDY OF TITUS ANDRONICUS  ...  THE TRAGEDY OF TITUS ANDRONICUS\\r\\n\\r\\nDramati...\n",
              "32       THE HISTORY OF TROILUS AND CRESSIDA  ...  THE HISTORY OF TROILUS AND CRESSIDA\\r\\n\\r\\n\\r\\...\n",
              "33          TWELFTH NIGHT; OR, WHAT YOU WILL  ...                                                   \n",
              "34          TWELFTH NIGHT: OR, WHAT YOU WILL  ...  TWELFTH NIGHT: OR, WHAT YOU WILL\\r\\n\\r\\n\\r\\n\\r...\n",
              "35                     THE TWO NOBLE KINSMEN  ...  THE TWO NOBLE KINSMEN:\\r\\n\\r\\nPresented at the...\n",
              "36                         THE WINTER’S TALE  ...  THE WINTER’S TALE\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nContents\\...\n",
              "37                       A LOVER’S COMPLAINT  ...  A LOVER’S COMPLAINT\\r\\n\\r\\n\\r\\n\\r\\nFrom off a ...\n",
              "38                    THE PASSIONATE PILGRIM  ...  THE PASSIONATE PILGRIM\\r\\n\\r\\nI.\\r\\n\\r\\nDid no...\n",
              "39                THE PHOENIX AND THE TURTLE  ...  THE PHOENIX AND THE TURTLE\\r\\n\\r\\n\\r\\n\\r\\nLet ...\n",
              "40                       THE RAPE OF LUCRECE  ...  THE RAPE OF LUCRECE\\r\\n\\r\\n                   ...\n",
              "41                          VENUS AND ADONIS  ...   VENUS AND ADONIS\\r\\n\\r\\nEven as the sun with ...\n",
              "42                                            ...                                                   \n",
              "\n",
              "[43 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa7bETCbIlth"
      },
      "source": [
        "# **Text Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpDB6xE1Jd4y"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords  \n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Dropout, SimpleRNN, LSTM\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "class TextCleaner:\n",
        "\n",
        "    def __init__(self, stop_word_type):\n",
        "        self.stop_word_type = stop_word_type\n",
        "\n",
        "    def download_stop_words(self):\n",
        "        nltk.download(self.stop_word_type)\n",
        "\n",
        "    def remove_punctuation(self, pattern, text):\n",
        "        sub = re.sub(pattern, \"\", text)\n",
        "        return sub\n",
        "    \n",
        "    def remove_special_characters(self, pattern, text):\n",
        "        sub = re.sub(pattern, \"\", text)\n",
        "        return sub\n",
        "\n",
        "    def remove_digits(self, pattern, text):\n",
        "        sub = re.sub(pattern, \"\", text)\n",
        "        return sub\n",
        "\n",
        "    def remove_white_space(self, text):\n",
        "        sub = re.sub(r\"\\s{2}\", \"\", text)\n",
        "        return sub\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        wrd_splitter = text.split()\n",
        "        return wrd_splitter\n",
        "\n",
        "    def remove_stop_words(\n",
        "        self, tokens,\n",
        "        language='english'):\n",
        "        stop_words = set(stopwords.words(language))\n",
        "        filtered_tokens = [word for word in tokens if not word in stop_words]  \n",
        "        return filtered_tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H21scqYCLPhU",
        "outputId": "36446c7a-e6a8-41c1-957b-12d29be8a766"
      },
      "source": [
        "tc = TextCleaner('stopwords')\n",
        "tc.download_stop_words()\n",
        "data = df_toc['text'][1:5]\n",
        "data = data.apply(lambda x: x.lower())\n",
        "data = data.apply(\n",
        "    lambda x: tc.remove_punctuation(r\"[\\[\\]\\-?\\\":&;'$\\\\*_/!@`%\\{\\}\\|\\(\\)]\", x))\n",
        "data = data.apply(\n",
        "    lambda x: tc.remove_digits(r\"[\\d]\", x))\n",
        "data = data.apply(\n",
        "    lambda x: tc.remove_special_characters(r\"(\\n)|(\\r)\", x))\n",
        "data = data.apply(\n",
        "    lambda x: tc.remove_white_space(x))\n",
        "data = data.apply(lambda x: x.encode('ascii', 'ignore'))\n",
        "data = data.apply(lambda x: x.decode('UTF-8'))\n",
        "data = data.apply(\n",
        "    lambda x: tc.tokenize(x))\n",
        "# data = data.apply(\n",
        "#     lambda x: tc.remove_stop_words(x))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOw80uGiRuyh"
      },
      "source": [
        "for e, i in enumerate(data):\n",
        "    if i == []:\n",
        "        data.drop(index=e, inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMllddWVLzUl"
      },
      "source": [
        "joined_text = []\n",
        "for text in data:\n",
        "    for word in text:\n",
        "        joined_text.append(word)\n",
        "\n",
        "joined_text = \" \".join(joined_text)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(joined_text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z3iUP5KaSb2",
        "outputId": "bd947b59-3e3a-40ff-93ec-9245a7966cab"
      },
      "source": [
        "int_char"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'j',\n",
              " 1: 'h',\n",
              " 2: 'q',\n",
              " 3: 'u',\n",
              " 4: 'v',\n",
              " 5: 'm',\n",
              " 6: '.',\n",
              " 7: 'y',\n",
              " 8: 'e',\n",
              " 9: 'c',\n",
              " 10: 'd',\n",
              " 11: 'w',\n",
              " 12: 'z',\n",
              " 13: 'g',\n",
              " 14: 'p',\n",
              " 15: 'l',\n",
              " 16: 'b',\n",
              " 17: 'n',\n",
              " 18: 'r',\n",
              " 19: ',',\n",
              " 20: 'i',\n",
              " 21: 'x',\n",
              " 22: 't',\n",
              " 23: 'o',\n",
              " 24: 'a',\n",
              " 25: ' ',\n",
              " 26: 'f',\n",
              " 27: 'k',\n",
              " 28: 's'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyIwdfjzYEUg",
        "outputId": "780ebc1f-92f1-476a-f659-3968a51d5568"
      },
      "source": [
        "# Create the sequence data\n",
        "maxlen = 50\n",
        "step = 7\n",
        "\n",
        "encoded = [char_int[c] for c in joined_text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))\n",
        "# print(encoded)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  72559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYsmtYaVeuJm"
      },
      "source": [
        "# Create x & y\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RNmI90tqbN1",
        "outputId": "600cf2b8-63ee-426b-c4ca-7c4078192ddf"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22662, 40, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an-qtfZmesyj"
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJwIvJLTjOm2"
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVcsmsXFhmgo"
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(joined_text) - maxlen - 1) \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = joined_text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EOw1jmvhqIK",
        "outputId": "21d9c000-db1b-4df4-cbe0-7585758fcf11"
      },
      "source": [
        "# fit the model\n",
        "model.fit(x, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2260/2268 [============================>.] - ETA: 0s - loss: 2.4601\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"sent that ipse is he now, you are not ipse, for ia\"\n",
            "sent that ipse is he now, you are not ipse, for ias wors meyks.henednst.ou waiwlss,gexlagthi, by ar tore lltit.sale plol.,hischy withesues nio fead be mecasenats an ancelcnrich.seselyy theare isunthoo, past ifud. awd sa thir winkmy add welh se waccestou.m, llytt tha lurn, to coreris wave yhe hat whes and,ind, lligem. belane gor miss gowe, ir ip ist af metsur. bunnt ruslo to come. sorstcongifd thavent.tuyulud sove.ucabssec circs anl ane sarcoy.ild\n",
            "2268/2268 [==============================] - 24s 11ms/step - loss: 2.4598\n",
            "Epoch 2/10\n",
            "2267/2268 [============================>.] - ETA: 0s - loss: 2.1468\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"phesus and his companions.adriana.within. who is t\"\n",
            "phesus and his companions.adriana.within. who is thencblagllo that hy sens tou thous.celus, hemeenitust rbe not. sofasting.nis indipher wiythe he shadth you berast, as shomd dhedchplacus. oflelinstingling. i quing. this ysusingent meapdend, mazendomond romlentelint. que povinttingint.se hemrog to now, hot gr arld pobler. wheve toundo. sfrether.cf calan safill mestwldmuststhe bake fark wall ipwest whehd forther my hor he dantord withsirnsen your i\n",
            "2268/2268 [==============================] - 25s 11ms/step - loss: 2.1468\n",
            "Epoch 3/10\n",
            "2261/2268 [============================>.] - ETA: 0s - loss: 2.0037\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"nd make the rabblecall our cares fears which will \"\n",
            "nd make the rabblecall our cares fears which will of thit how antiube unken.couiss, shall do drued blay pray and wis that hinest and to lleat.are be preesithou here go.icalus of so pare,ti sitreftollesinghous awrmas, not jordes for inthe kill may,mballmonse you, for hor hour thee vid issel. hivene the sand hime.untia.come not couse is noble geove youd hisly.ale thay praisse, meeln you,forour. hir paicons of chusus. i mathers lord,with i whacl the\n",
            "2268/2268 [==============================] - 24s 11ms/step - loss: 2.0036\n",
            "Epoch 4/10\n",
            "2262/2268 [============================>.] - ETA: 0s - loss: 1.8975\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"they say theres grain enoughwould the nobility lay\"\n",
            "they say theres grain enoughwould the nobility lay he th eny,os the paikfhillbrioni. ding the sallare then my comp.wiy are your nats feners, in thou of a durds, friphher gond no wariltwhers thouls not hawn hor hin dilds meall what she covin our fis of mughor is hear im. if so dillbent to hin connethume.cando. poren corsest with than sted postronge magh as he be shor do ill with this thou nover in fear tend becong now, brage doesh, and ifker what \n",
            "2268/2268 [==============================] - 24s 11ms/step - loss: 1.8973\n",
            "Epoch 5/10\n",
            "2267/2268 [============================>.] - ETA: 0s - loss: 1.8153\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"d, o, how comes it,that thou art then estranged fr\"\n",
            "d, o, how comes it,that thou art then estranged friasecor, so.acturn. rysen, wher my herhogesbould in mo comender with has so groman undergomeis, ane youm hou celfwor it hemacst in. wiss and the withan offerel.. int the briownot cart mone stink a day my chould being this gove what to num hear the spoar him tiak so rosely, and dostloms ame part al courpesalind tush beasanatyoo spencousd fartstard herice you not is my coris i is manging this not sp\n",
            "2268/2268 [==============================] - 24s 11ms/step - loss: 1.8153\n",
            "Epoch 6/10\n",
            "2263/2268 [============================>.] - ETA: 0s - loss: 1.7486\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \" i gainst thee lookfor fury not to be resisted. th\"\n",
            " i gainst thee lookfor fury not to be resisted. them wuth nof them whech whenes will me of my it, rave be raviontnou boand am pass,or doon and monest lofe. extt, low in faly, pace you lave blowe inverd you coomtupes be tor pwareast hean posalfitse than list it both domesto the baros and bo bleasd.for these whomes in than so digal mir ancortous wist st dik we sould unoo my bobrentthe vorsembelymy fralet you the volety foubbert.ongflet. the disceti\n",
            "2268/2268 [==============================] - 24s 11ms/step - loss: 1.7487\n",
            "Epoch 7/10\n",
            "2259/2268 [============================>.] - ETA: 0s - loss: 1.6910\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \" to shift it. have i hurt himsecond lord.aside. no\"\n",
            " to shift it. have i hurt himsecond lord.aside. not sur enter frianiss capoteeck iver and so ty may, comilius lords, the natuse us promn.tiget be to piten, and will pry to thee.comiays comes.very secving well,what celar, atwetthuchsmenstonger secole. selvce.i an kely pacelie. entel.consien, court. their would to the baridorsade sim, is thisisibe sack seeps, if gose the kenseind ip sir the midreris fell.blernius.wo heact of hermcome is our in tdir\n",
            "2268/2268 [==============================] - 24s 10ms/step - loss: 1.6911\n",
            "Epoch 8/10\n",
            "2262/2268 [============================>.] - ETA: 0s - loss: 1.6422\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \" parchment, and the blows you gave were ink,your o\"\n",
            " parchment, and the blows you gave were ink,your othis his tellaving. britce his stifl that wish rastersand alleyto bray your fididingelfon that ths mehe thing tiancy gaants you vorgh. liss, no beagless master i seck you,whe seich my fhold wele,i have bestill nomseftheresa dad falleding wull the but ad hank, and will hees ableravorruy,fay to cotten steer hand on wheeedhe oned ristray, it me the dcedticemany fot rend if paremine aw in tas murtke e\n",
            "2268/2268 [==============================] - 24s 11ms/step - loss: 1.6417\n",
            "Epoch 9/10\n",
            "2263/2268 [============================>.] - ETA: 0s - loss: 1.5940\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"onds in sunder,i gaind my freedom and immediatelyr\"\n",
            "onds in sunder,i gaind my freedom and immediatelyravives tay sleand he with thou britont, fall his not on itsie, most day we prest, you see madest ore that seef my hervine.sleas in foom sumong frow not bebound comes of a bellfor whats out nog por fellsha gade. well not you that so winciout instow it fould foed,we are some.there precesti,try pated king.buting is farth marry prack when incwill pricileans, is beer, of my age and gake ane press, whow\n",
            "2268/2268 [==============================] - 24s 11ms/step - loss: 1.5941\n",
            "Epoch 10/10\n",
            "2258/2268 [============================>.] - ETA: 0s - loss: 1.5522\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"a syracusian merchantis apprehended for arrival he\"\n",
            "a syracusian merchantis apprehended for arrival her friends indrat entrantentss kenter her a poors think os than bletter. bo courtiye to cearus more dindesponates. not will me. crieslant with maid you know in taichdrows,thanwill retor them and crains and i warly,and prevelaft the compthis of shall you roman and goars ithou shake grangene senateshat noth terr pun sheros in thoun percctoust with like him and as yaget one all them in phave in she on\n",
            "2268/2268 [==============================] - 24s 11ms/step - loss: 1.5525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92fee1b2e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "zZ2FO7bWlds-",
        "outputId": "18648f38-2537-41b9-9efe-7c55a730621c"
      },
      "source": [
        "model.predict(\"yonder window\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a31a18638e10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yonder window\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    885\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}